{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'色泽': {'青绿': {'敲声': {'浊响': '是', '清脆': '否', '沉闷': '否'}}, '乌黑': {'根蒂': {'硬挺': '是', '蜷缩': '是', '稍蜷': {'纹理': {'模糊': '是', '稍糊': '是', '清晰': '否'}}}}, '浅白': '否'}}\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#决策树 ID3算法\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "def entropy(labels):\n",
    "    data_length=len(labels)\n",
    "    result={}\n",
    "    for each in labels:\n",
    "        result[each]=result.get(each,0)+1\n",
    "    ent=0\n",
    "    for v in result.values():\n",
    "        ent-=v/data_length*log2(v/data_length)\n",
    "        \n",
    "    return ent\n",
    "\n",
    "#计算每一个属性的信息增益\n",
    "def calcu_each_gain(column,update_data):\n",
    "    total=len(column)\n",
    "    #以特征列为基准来分组标签\n",
    "    grouped=update_data.iloc[:,-1].groupby(by=column)\n",
    "    \n",
    "    #for g in list(grouped):\n",
    "    #    con_ent+=len(g[1])/total*entropy(g[1])\n",
    "    con_ent=sum ([len(g[1])/total*entropy(g[1]) for g in list(grouped)])\n",
    "    return entropy(update_data.iloc[:,-1])-con_ent\n",
    "\n",
    "#      找到最大增益作为分支准则\n",
    "#返回（属性，增益）\n",
    "def get_max_gain(temp_data):\n",
    "    \n",
    "    #计算每一个特征的增益，排序找出最大值\n",
    "    #for feature_name in temp_data[:,:-1]取出的是属性名\n",
    "    columns_entropy=[(feature,calcu_each_gain(temp_data[feature],temp_data))  for feature in temp_data.iloc[:,:-1].columns]\n",
    "    columns_entropy=sorted(columns_entropy,key=lambda f: f[1], reverse=True)\n",
    "    return columns_entropy[0]\n",
    "\n",
    "\n",
    "#去掉数据中已存在的列属性内容\n",
    "#并返回其每一个子节点对应的属性及样本数据\n",
    "def drop_exist_feature(data,best_feature):\n",
    "    attr=pd.unique(data[best_feature])\n",
    "    new_data = [(nd, data[data[best_feature] == nd]) for nd in attr]\n",
    "    new_data = [(n[0], n[1].drop([best_feature], axis=1)) for n in new_data]\n",
    "    return new_data\n",
    "\n",
    "#获取最多的label\n",
    "def get_most_label(label_list):\n",
    "    label_dict={}\n",
    "    for i in label_list:\n",
    "        label_dict[i]=label_dict.get(i,0)+1\n",
    "    sorted_label=sorted(label_dict.items(),key=lambda t: t[1], reverse=True)\n",
    "    #items返回的是一个元祖形式，（keys,values），key=lambda是将key函数应用于待排序元祖，再进行排序\n",
    "    return sorted_label[0][0]\n",
    "\n",
    "#创建决策树\n",
    "#data_set为数据集\n",
    "#column_count为属性特征集合\n",
    "\n",
    "def create_tree(data_set,column_count):\n",
    "    label_list=data_set.iloc[:,-1]#取出标签类\n",
    "    if len(pd.unique(label_list))==1:\n",
    "        #当前结点样本完全属于同一类，返回叶结点\n",
    "        return label_list.values[0]\n",
    "    if all([len(pd.unique(data_set[i]))==1 for i in data_set.iloc[:,:-1].columns]):\n",
    "        #如果在特征上取值均相同则返回True\n",
    "        #如果数据属性为空，则相当于all([]),也是返回True,即返回叶结点\n",
    "        #某一属性下面只有一种特征，不可再分，返回叶结点，类标为种类最多的点\n",
    "        return get_most_label(label_list)\n",
    "    best_attr=get_max_gain(data_set)[0]\n",
    "    #返回分支表现最好的属性名\n",
    "    tree={best_attr:{}}\n",
    "    #最好的属性下面的特征\n",
    "    exist_attr=pd.unique(data_set[best_attr])\n",
    "    #column_count为属性及特征集合\n",
    "    if len(exist_attr)!=len(column_count[best_attr]):\n",
    "        #即属性中某一特征的样本集为空\n",
    "        no_exist_attr=set(column_count[best_attr])-set(exist_attr)\n",
    "        for nea in no_exist_attr:\n",
    "            tree[best_attr][nea]=get_most_label(label_list)\n",
    "    for item in drop_exist_feature(data_set,best_attr):\n",
    "        #item[0]为best_attr可能的取值\n",
    "        tree[best_attr][item[0]]=create_tree(item[1],column_count)\n",
    "    return tree\n",
    "\n",
    "\n",
    "#用训练完成的DT预测数据\n",
    "def classify(Tree, feature_names, test_data):\n",
    "    classLabel=''\n",
    "    #取出根结点\n",
    "    root = list(Tree.keys())[0]\n",
    "    #取出第一棵树\n",
    "    firstDict = Tree[root]\n",
    "    feature_index = feature_names.index(root)  #根节点的属性下标\n",
    "    \n",
    "    for key in firstDict.keys():   #根属性的取值,取哪个就走往哪颗子树,指定子树的走向\n",
    "        if test_data[feature_index] == key:\n",
    "            if type(firstDict[key]) == type({}):\n",
    "                classLabel = classify(firstDict[key],feature_names,test_data)\n",
    "            else:\n",
    "                classLabel = firstDict[key]\n",
    "    return classLabel\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    my_data = pd.read_csv(r'E:\\Repository\\algorithms\\xiguatest.txt',sep=',')\n",
    "    column_count = dict([(ds, list(pd.unique(my_data[ds]))) for ds in my_data.iloc[:,:-1].columns])\n",
    "    feature_names=list(my_data.iloc[:,:-1].columns)\n",
    "    d_tree = create_tree(my_data, column_count)\n",
    "    \n",
    "    \n",
    "    #print(d_tree)\n",
    "    #print(feature_names.index('纹理'))\n",
    "    #root=list(d_tree.keys())[0]\n",
    "    #firstdict=d_tree[root]\n",
    "    #create_plot(d_tree)       \n",
    "    print(d_tree)\n",
    "    test_data=pd.read_csv(r'E:\\Repository\\algorithms\\xigua1.txt',sep=',')\n",
    "    test=test_data.iloc[:,:].values\n",
    "    for test_data in test:\n",
    "        class_label=classify(d_tree, feature_names, test_data[0:-1])\n",
    "        if class_label==test_data[-1]:\n",
    "            print(True)\n",
    "        else:\n",
    "            print(False)\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['青绿' '蜷缩' '沉闷' '稍糊' '稍凹' '硬滑']\n",
      "['浅白' '蜷缩' '浊响' '清晰' '凹陷' '硬滑']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_data=pd.read_csv(r'E:\\Repository\\algorithms\\xigua1.txt',sep=',')\n",
    "a=test_data.iloc[:,:].values\n",
    "for i in a:\n",
    "    print(i[0:-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
